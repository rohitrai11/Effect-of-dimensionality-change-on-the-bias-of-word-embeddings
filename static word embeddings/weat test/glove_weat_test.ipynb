{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67332c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import GloVe\n",
    "import torch\n",
    "import numpy as np\n",
    "import nltk\n",
    "from vocabulary import Vocabulary\n",
    "import pickle\n",
    "import csv \n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7541b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['target_one vs target_two', 'attribute_one vs attribute_two', 'd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d27f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_200d = GloVe(400000, 200, 100, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fdda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_100d = GloVe(400000, 100, 100, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3fa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_50d = GloVe(400000, 50, 100, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb2196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_200d.load_state_dict(torch.load('/home/rrr/Desktop/glove_code_final/embeddings_200d.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e831eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_100d.load_state_dict(torch.load('/home/rrr/Desktop/glove_code_final/embeddings_100d.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e5db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_50d.load_state_dict(torch.load('/home/rrr/Desktop/glove_code_final/embeddings_50d.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157a14e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "with open('/home/rrr/Desktop/glove_code_final/cooccurrence_dir/vocab.pkl', 'rb') as file:\n",
    "    # Load the object from the file using pickle.load()\n",
    "    my_object = pickle.load(file)\n",
    "\n",
    "print(len(my_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b70fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"weat.txt\", \"r\" ) \n",
    "file=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b83a1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(file.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05800f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "  # if(x is not None):\n",
    "  #   if(y is not None):\n",
    "  #     num = np.dot(x, y)\n",
    "  #     a = np.linalg.norm(x)\n",
    "  #     b = np.linalg.norm(y)\n",
    "  #     den = a*b\n",
    "  #     res = num/den\n",
    "  #     return res\n",
    "  return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d963cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "mean_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4f1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_attribute(target_one,target_two, target_one_words, attribute_one,attribute_two, \n",
    "                     attribute_one_words, target_two_words, attribute_two_words, model):\n",
    "        cos=[]\n",
    "        s=0\n",
    "        s1=[]\n",
    "        s2=[]\n",
    "        S=[]\n",
    "        n=0\n",
    "        for i in range(0, len(target_one_words)):\n",
    "          c1=[]\n",
    "          c2=[]\n",
    "          for k in range(0, len(attribute_one_words)):\n",
    "            wt = target_one_words[i][:-1]\n",
    "            at1 = attribute_one_words[k][:-1]\n",
    "            ind_wt = my_object.get_index(wt)\n",
    "            ind_at1 = my_object.get_index(at1)\n",
    "            \n",
    "            try:\n",
    "              x = model.weight(torch.tensor(ind_wt))\n",
    "              y = model.weight(torch.tensor(ind_at1))\n",
    "              x = x.detach().numpy()\n",
    "              y = y.detach().numpy()\n",
    "              cos1= cosine_similarity(x, y)\n",
    "              cos.append(cos1)\n",
    "              c1.append(cos1)\n",
    "            except:\n",
    "              cos1=0\n",
    "              cos.append(cos1)\n",
    "              c1.append(cos1)\n",
    "              continue\n",
    "              \n",
    "          for k in range(0, len(attribute_two_words)):\n",
    "            cos2=0\n",
    "            wt = target_one_words[i][:-1]\n",
    "            at2 = attribute_two_words[k][:-1]\n",
    "            ind_wt = my_object.get_index(wt)\n",
    "            ind_at2 = my_object.get_index(at2)\n",
    "            \n",
    "            try:\n",
    "              x = model.weight(torch.tensor(ind_wt))\n",
    "              y = model.weight(torch.tensor(ind_at2))\n",
    "              x = x.detach().numpy()\n",
    "              y = y.detach().numpy()\n",
    "              cos2= cosine_similarity(x, y)\n",
    "              cos.append(cos2)\n",
    "              c2.append(cos2)\n",
    "            except:\n",
    "              cos2=0\n",
    "              cos.append(cos2)\n",
    "              c2.append(cos2)\n",
    "              continue\n",
    "          s1.append((np.mean(c1)-np.mean(c2)))\n",
    "          S.append((np.mean(c1)-np.mean(c2)))\n",
    "          n=n+1\n",
    "            \n",
    "        for i in range(0, len(target_two_words)):\n",
    "          c1=[]\n",
    "          c2=[]\n",
    "\n",
    "          for k in range(0, len(attribute_one_words)):\n",
    "            wt = target_two_words[i][:-1]\n",
    "            at1 = attribute_one_words[k][:-1]\n",
    "            ind_wt = my_object.get_index(wt)\n",
    "            ind_at1 = my_object.get_index(at1)\n",
    "            \n",
    "            try:\n",
    "              x = model.weight(torch.tensor(ind_wt))\n",
    "              y = model.weight(torch.tensor(ind_at1))\n",
    "              x = x.detach().numpy()\n",
    "              y = y.detach().numpy()\n",
    "              cos1= cosine_similarity(x, y)\n",
    "              cos.append(cos1)\n",
    "              c1.append(cos1)\n",
    "            except:\n",
    "              cos1=0\n",
    "              cos.append(cos1)\n",
    "              c1.append(cos1)\n",
    "              continue\n",
    "            \n",
    "          for k in range(0, len(attribute_two_words)):\n",
    "            cos2=0\n",
    "            wt = target_two_words[i][:-1]\n",
    "            at2 = attribute_two_words[k][:-1]\n",
    "            wt = target_one_words[i][:-1]\n",
    "            at2 = attribute_two_words[k][:-1]\n",
    "            ind_wt = my_object.get_index(wt)\n",
    "            ind_at2 = my_object.get_index(at2)\n",
    "            \n",
    "            try:\n",
    "              x = model.weight(torch.tensor(ind_wt))\n",
    "              y = model.weight(torch.tensor(ind_at2))\n",
    "              x = x.detach().numpy()\n",
    "              y = y.detach().numpy()\n",
    "              cos2= cosine_similarity(x, y)\n",
    "              cos.append(cos2)\n",
    "              c2.append(cos2)\n",
    "            except:\n",
    "              cos2=0\n",
    "              cos.append(cos2)\n",
    "              c2.append(cos2)\n",
    "              continue\n",
    "          s2.append((np.mean(c1)-np.mean(c2)))\n",
    "          S.append((np.mean(c1)-np.mean(c2)))\n",
    "        s=np.sum(s1)-np.sum(s2)\n",
    "        stdev=np.std(S)\n",
    "        res = s/(stdev*n)\n",
    "        \n",
    "        if(target_one == 'european_american_names'):\n",
    "            res2 = '%.2f' % res\n",
    "            mean_list.append(res2)\n",
    "            \n",
    "            if(len(mean_list) == 3):\n",
    "                p = []\n",
    "                val1 = target_one + ' vs ' + target_two\n",
    "                p.append(val1)\n",
    "            \n",
    "                val2 = attribute_one + ' vs ' + attribute_two\n",
    "                p.append(val2)\n",
    "                \n",
    "                float_mean_list = []\n",
    "                for val in mean_list:\n",
    "                    float_mean_list.append(float(val))\n",
    "            \n",
    "                avg = statistics.mean(float_mean_list)\n",
    "                res2 = '%.2f' % avg\n",
    "                p.append(res2)\n",
    "                rows.append(p)\n",
    "                \n",
    "        else:\n",
    "            p = []\n",
    "\n",
    "            val1 = target_one + ' vs ' + target_two\n",
    "            p.append(val1)\n",
    "\n",
    "            val2 = attribute_one + ' vs ' + attribute_two\n",
    "            p.append(val2)\n",
    "\n",
    "            #print(target_one + ' vs ' + target_two  + ' , ' +attribute_one + ' vs ' + attribute_two +', d = ',end=\"\")\n",
    "            #print('%.2f' % res)\n",
    "            res2 = '%.2f' % res\n",
    "            p.append(res2)\n",
    "\n",
    "            rows.append(p)\n",
    "        #print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd46f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_sentences)-30):\n",
    "    words=raw_sentences[i*4].split()\n",
    "    target_one = words[0][:-1]\n",
    "    target_one_words = words[1:]\n",
    "    words1=raw_sentences[i*4+1].split()\n",
    "    target_two = words1[0][:-1]\n",
    "    target_two_words = words1[1:]\n",
    "    words2=raw_sentences[i*4+2].split()\n",
    "    attribute_one = words2[0][:-1]\n",
    "    attribute_one_words = words2[1:]\n",
    "    words3 = raw_sentences[i*4+3].split()\n",
    "    attribute_two = words3[0][:-1]\n",
    "    attribute_two_words = words3[1:]\n",
    "    \n",
    "    target_attribute(target_one,target_two, target_one_words, attribute_one,attribute_two, \n",
    "                     attribute_one_words, target_two_words, attribute_two_words, embed_200d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of csv file \n",
    "filename = \"results_glove_200d.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c994d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "        \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a78697",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "mean_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "079d25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_sentences)-30):\n",
    "    words=raw_sentences[i*4].split()\n",
    "    target_one = words[0][:-1]\n",
    "    target_one_words = words[1:]\n",
    "    words1=raw_sentences[i*4+1].split()\n",
    "    target_two = words1[0][:-1]\n",
    "    target_two_words = words1[1:]\n",
    "    words2=raw_sentences[i*4+2].split()\n",
    "    attribute_one = words2[0][:-1]\n",
    "    attribute_one_words = words2[1:]\n",
    "    words3 = raw_sentences[i*4+3].split()\n",
    "    attribute_two = words3[0][:-1]\n",
    "    attribute_two_words = words3[1:]\n",
    "    \n",
    "    target_attribute(target_one,target_two, target_one_words, attribute_one,attribute_two, \n",
    "                     attribute_one_words, target_two_words, attribute_two_words, embed_100d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a15fc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of csv file \n",
    "filename = \"results_glove_100d.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9df8f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "        \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
