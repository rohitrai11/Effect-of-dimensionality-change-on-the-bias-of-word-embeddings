{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43696193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db07521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78031450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0e5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file = \"options_file_128d.json\"\n",
    "weights_file = \"elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da04f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elmo = Elmo(options_file, weights_file, num_output_representations=1, dropout=0.5)\n",
    "elmo = Elmo(options_file, weights_file, num_output_representations=1, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6d6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(sent,word):\n",
    "  tokens = word_tokenize(sent)\n",
    "  token_ids = batch_to_ids([tokens])\n",
    "  elmo_representations = elmo(token_ids)\n",
    "  embeddings = elmo_representations['elmo_representations']\n",
    "  \n",
    "  # Convert the ELMo representations to a list of PyTorch tensors\n",
    "  elmo_tensors = elmo_representations['elmo_representations']\n",
    "\n",
    "  # Convert each tensor to a NumPy array\n",
    "  embeddings_array = [tensor.detach().numpy() for tensor in elmo_tensors]\n",
    "\n",
    "  # Concatenate the arrays along the last axis to get the final embeddings\n",
    "  embeddings_array = np.concatenate(embeddings_array, axis=-1)\n",
    "\n",
    "  for i in range(len(tokens)):\n",
    "    if(tokens[i] == word):\n",
    "      return embeddings_array[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd56ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v = get_word_vector(\"The flower is beautiful\",\"flower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623a6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b64f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effect_size(df1, df2, k=\"bias_prior_corrected\"):\n",
    "    diff = (df1[k].mean() - df2[k].mean())\n",
    "    std_ = pd.concat([df1, df2], axis=0)[k].std() + 1e-8\n",
    "    return diff / std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f65103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "  # if(x is not None):\n",
    "  #   if(y is not None):\n",
    "  #     num = np.dot(x, y)\n",
    "  #     a = np.linalg.norm(x)\n",
    "  #     b = np.linalg.norm(y)\n",
    "  #     den = a*b\n",
    "  #     res = num/den\n",
    "  #     return res\n",
    "  return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2781c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_bias_scores(targets, A, B, sentences, group=True):\n",
    "    wvs_targets = [\n",
    "        (t, get_word_vector(sentence.replace(\"GGG\", t), t) )\n",
    "        for sentence in sentences\n",
    "        for t in targets\n",
    "    ]\n",
    "    wvs_A = [\n",
    "        get_word_vector(sentence.replace(\"XXX\", a), a) \n",
    "        for sentence in sentences\n",
    "        for a in A\n",
    "    ]\n",
    "    wvs_B = [\n",
    "        get_word_vector(sentence.replace(\"XXX\", b), b) \n",
    "        for sentence in sentences\n",
    "        for b in B\n",
    "    ]\n",
    "    df1 = pd.DataFrame([\n",
    "        {\"target\": t, \"score\": cosine_similarity(wv, wva)}\n",
    "        for wva in wvs_A\n",
    "        for t, wv in wvs_targets\n",
    "    ])\n",
    "    if group: df1 = df1.groupby(\"target\").mean()[\"score\"].reset_index()\n",
    "    df2 = pd.DataFrame([\n",
    "        {\"target\": t, \"score\": cosine_similarity(wv, wvb)}\n",
    "        for wvb in wvs_B\n",
    "        for t, wv in wvs_targets\n",
    "    ])\n",
    "    if group: df2 = df2.groupby(\"target\").mean()[\"score\"].reset_index()\n",
    "    df = df1.copy()\n",
    "    df[\"bias_prior_corrected\"] = df1[\"score\"] - df2[\"score\"]\n",
    "    return df[[\"target\", \"bias_prior_corrected\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33bf27f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "flower_words = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', 'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil', 'lilac', 'pansy', 'tulip', 'buttercup', 'daisy', 'lily', 'peony', 'violet', 'carnation', 'gladiola',\n",
    "'magnolia', 'petunia', 'zinnia']\n",
    "\n",
    "insect_words = ['ant', 'caterpillar', 'flea', 'locust', 'spider', 'bedbug', 'centipede', 'fly', 'maggot', 'tarantula',\n",
    "'bee', 'cockroach', 'gnat', 'mosquito', 'termite', 'beetle', 'cricket', 'hornet', 'moth', 'wasp', 'blackfly',\n",
    "'dragonfly', 'horsefly', 'roach', 'weevil']\n",
    "\n",
    "\n",
    "print(len(flower_words) == len(insect_words))\n",
    "\n",
    "#attribute words\n",
    "pleasant_words = ['caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure', 'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise', 'family',\n",
    "'happy', 'laughter', 'paradise', 'vacation']\n",
    "\n",
    "\n",
    "unpleasant_words = ['abuse', 'crash', 'filth', 'murder', 'sickness', 'accident', 'death', 'grief', 'poison', 'stink',\n",
    "'assault', 'disaster', 'hatred', 'pollute', 'tragedy', 'divorce', 'jail', 'poverty', 'ugly', 'cancer', 'kill', 'rotten',\n",
    "'vomit', 'agony', 'prison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c5e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowers vs. Insects :  1.0612258029604205\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(flower_words, pleasant_words, \n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(insect_words, pleasant_words, \n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"Flowers vs. Insects : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e75f7c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "instruments = [\"bagpipe\", \"cello\", \"guitar\", \"lute\", \"trombone\", \"banjo\", \"clarinet\", \"harmonica\",\n",
    "               \"mandolin\", \"trumpet\", \"bassoon\", \"drum\", \"harp\", \"oboe\", \"tuba\", \"bell\", \"fiddle\", \"harpsichord\", \"piano\", \"viola\",\n",
    "               \"bongo\", \"flute\", \"horn\", \"saxophone\", \"violin\"]\n",
    "\n",
    "weapons = [\"arrow\", \"club\", \"gun\", \"missile\", \"spear\", \"axe\", \"dagger\", \"harpoon\", \"pistol\", \"sword\", \"blade\", \"dynamite\", \"hatchet\", \"rifle\", \"tank\",\n",
    "           \"bomb\", \"firearm\", \"knife\", \"shotgun\", \"teargas\", \"cannon\", \"grenade\", \"mace\", \"slingshot\", \"whip\"]\n",
    "\n",
    "print(len(instruments)==len(weapons))\n",
    "#weapons[:len(instruments)]\n",
    "\n",
    "#attribute words\n",
    "pleasant_words = ['caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure', 'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise', 'family',\n",
    "'happy', 'laughter', 'paradise', 'vacation']\n",
    "\n",
    "unpleasant_words = ['abuse', 'crash', 'filth', 'murder', 'sickness', 'accident', 'death', 'grief', 'poison', 'stink',\n",
    "'assault', 'disaster', 'hatred', 'pollute', 'tragedy', 'divorce', 'jail', 'poverty', 'ugly', 'cancer', 'kill', 'rotten',\n",
    "'vomit', 'agony', 'prison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "280d143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruments vs. Weapons :  1.7704338029080178\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(instruments, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(weapons, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"Instruments vs. Weapons : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc217900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "european_american_nams = [\"Adam\", \"Chip\", \"Harry\", \"Josh\", \"Roger\", \"Alan\", \"Frank\", \"Ian\", \"Justin\", \"Ryan\", \"Andrew\", \"Fred\",\n",
    "                           \"Jack\", \"Matthew\", \"Stephen\", \"Brad\", \"Greg\", \"Jed\", \"Paul\", \"Todd\", \"Brandon\", \"Hank\", \"Jonathan\", \"Peter\",\n",
    "                           \"Wilbur\", \"Amanda\", \"Courtney\", \"Heather\", \"Melanie\", \"Sara\", \"Amber\", \"Crystal\", \"Katie\", \"Meredith\", \"Shannon\",\n",
    "                          \"Betsy\", \"Donna\", \"Kristin\", \"Nancy\", \"Stephanie\", \"Bobbie-Sue\", \"Ellen\", \"Lauren\", \"Peggy\", \"Sue-Ellen\",\n",
    "                           \"Colleen\", \"Emily\", \"Megan\", \"Rachel\", \"Wendy\"]\n",
    "\n",
    "african_american_nams = [\"Alonzo\", \"Jamel\", \"Lerone\", \"Percell\", \"Theo\",\"Alphonse\", \"Jerome\", \"Leroy\", \"Rasaan\", \"Torrance\", \"Darnell\", \"Lamar\",\n",
    "                          \"Lionel\", \"Rashaun\", \"Tyree\", \"Deion\", \"Lamont\", \"Malik\", \"Terrence\", \"Tyrone\", \"Everol\", \"Lavon\", \"Marcellus\", \"Terryl\",\n",
    "                          \"Wardell\", \"Aiesha\", \"Lashelle\", \"Nichelle\", \"Shereen\", \"Temeka\", \"Ebony\", \"Latisha\", \"Shaniqua\", \"Tameisha\", \"Teretha\",\n",
    "                          'Jasmine', \"Latonya\", \"Shanise\", \"Tanisha\", \"Tia\", \"Lakisha\", \"Latoya\", \"Sharise\", \"Tashika\", \"Yolanda\", \"Lashandra\", \"Malika\",\n",
    "                          \"Shavonn\", \"Tawanda\", \"Yvette\"]\n",
    "\n",
    "\n",
    "#attribute words\n",
    "european_american_names = [word.lower() for word in european_american_nams]\n",
    "\n",
    "african_american_names = [word.lower() for word in african_american_nams]\n",
    "\n",
    "print(len(european_american_names) == len(african_american_names))\n",
    "\n",
    "pleasant_words = ['caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure', 'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise', 'family',\n",
    "'happy', 'laughter', 'paradise', 'vacation']\n",
    "\n",
    "\n",
    "unpleasant_words = ['abuse', 'crash', 'filth', 'murder', 'sickness', 'accident', 'death', 'grief', 'poison', 'stink',\n",
    "'assault', 'disaster', 'hatred', 'pollute', 'tragedy', 'bomb', 'divorce', 'jail', 'poverty', 'ugly', 'cancer', 'evil', 'kill', 'rotten', 'vomit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af5b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "european_american_names vs. african_american_names :  0.35695156225400976\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(european_american_names, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(african_american_names, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"european_american_names vs. african_american_names : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e53e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "european_american_nams = [\"Brad\", \"Brendan\", \"Geoffrey\", \"Greg\", \"Brett\", \"Jay\", \"Matthew\", \"Neil\",\n",
    " \"Todd\", \"Allison\", \"Anne\", \"Carrie\", \"Emily\", \"Jill\", \"Laurie\", \"Kristen\", \"Meredith\", \"Sarah\"]\n",
    "\n",
    "african_american_nams = [\"Darnell\", \"Hakim\", \"Jermaine\", \"Kareem\", \"Jamal\", \"Leroy\", \"Rasheed\", \"Tremayne\", \"Tyrone\", \"Aisha\",\n",
    "\"Ebony\", \"Keisha\", \"Kenya\", \"Latonya\", \"Lakisha\", \"Latoya\", \"Tamika\", \"Tanisha\"]\n",
    "\n",
    "european_american_names = [word.lower() for word in european_american_nams]\n",
    "\n",
    "african_american_names = [word.lower() for word in african_american_nams]\n",
    "\n",
    "print(len(european_american_names) == len(african_american_names))\n",
    "#attribute words\n",
    "\n",
    "pleasant_words = ['caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure', 'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise', 'family',\n",
    "'happy', 'laughter', 'paradise', 'vacation']\n",
    "\n",
    "\n",
    "unpleasant_words = ['abuse', 'crash', 'filth', 'murder', 'sickness', 'accident', 'death', 'grief', 'poison', 'stink',\n",
    "'assault', 'disaster', 'hatred', 'pollute', 'tragedy', 'bomb', 'divorce', 'jail', 'poverty', 'ugly', 'cancer', 'evil', 'kill', 'rotten', 'vomit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9231e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "european_american_names vs. african_american_names :  0.6483765446798473\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(european_american_names, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(african_american_names, pleasant_words,\n",
    "                           unpleasant_words, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"european_american_names vs. african_american_names : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50d3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "european_american_nams = [\"Brad\", \"Brendan\", \"Geoffrey\", \"Greg\", \"Brett\", \"Jay\", \"Matthew\", \"Neil\",\n",
    " \"Todd\", \"Allison\", \"Anne\", \"Carrie\", \"Emily\", \"Jill\", \"Laurie\", \"Kristen\", \"Meredith\", \"Sarah\"]\n",
    "\n",
    "african_american_nams = [\"Darnell\", \"Hakim\", \"Jermaine\", \"Kareem\", \"Jamal\", \"Leroy\", \"Rasheed\", \"Tremayne\", \"Tyrone\", \"Aisha\",\n",
    "\"Ebony\", \"Keisha\", \"Kenya\", \"Latonya\", \"Lakisha\", \"Latoya\", \"Tamika\", \"Tanisha\"]\n",
    "\n",
    "european_american_names = [word.lower() for word in european_american_nams]\n",
    "\n",
    "african_american_names = [word.lower() for word in african_american_nams]\n",
    "\n",
    "\n",
    "print(len(european_american_names) == len(african_american_names))\n",
    "#attribute words\n",
    "pleasant = [\"joy\", \"love\", \"peace\", \"wonderful\", \"pleasure\", \"friend\", \"laughter\", \"happy\"]\n",
    "\n",
    "\n",
    "unpleasant = [\"agony\", \"terrible\", \"horrible\", \"nasty\", \"evil\", \"war\", \"awful\", \"failure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "376cec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "european_american_names vs. african_american_names :  0.8236818849949046\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(european_american_names, pleasant,\n",
    "                           unpleasant, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(african_american_names, pleasant,\n",
    "                           unpleasant, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"european_american_names vs. african_american_names : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb52cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "male_words = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
    "\n",
    "female_words = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
    "\n",
    "print(len(male_words) == len(female_words))\n",
    "\n",
    "#attribute words\n",
    "career_words = ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']\n",
    "\n",
    "family_words = ['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e62420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career vs Family :  0.025321991883332375\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(male_words, career_words, \n",
    "                           family_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(female_words, family_words, \n",
    "                           family_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "print(\"Career vs Family : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ce0f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#attribute words\n",
    "math_words = [\"math\", \"algebra\", \"geometry\", \"calculus\", \"equations\", \"computation\", \"numbers\", \"addition\"]\n",
    "\n",
    "art_words = [\"poetry\", \"art\", \"dance\", \"shakespear\", \"literature\", \"novels\", \"symphony\", \"drama\"]\n",
    "\n",
    "print(len(math_words) == len(art_words))\n",
    "\n",
    "#target words\n",
    "male_words = [\"male\", \"man\", \"boy\", \"brother\", \"son\", \"he\", \"his\", \"him\"]\n",
    "\n",
    "female_words = [\"female\", \"woman\", \"girl\", \"sister\", \"daughter\", \"she\", \"her\", \"hers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "479648a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math vs Art :  0.4184630915672526\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(male_words, math_words,\n",
    "                           art_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(female_words, math_words,\n",
    "                           art_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "print(\"Math vs Art : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9173236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "male_words = [\"brother\", \"father\", \"uncle\", \"grandfather\", \"son\", \"he\", \"his\", \"him\"]\n",
    "\n",
    "female_words = [\"sister\", \"mother\", \"aunt\", \"grandmother\", \"daughter\", \"she\", \"hers\", \"her\"]\n",
    "\n",
    "print(len(male_words) == len(female_words))\n",
    "#attribute words\n",
    "\n",
    "science_words = [\"science\", \"technology\", \"physics\", \"chemistry\", \"einstein\", \"nasa\", \"experiments\", \"astronomy\"]\n",
    "\n",
    "art_words = [\"poetry\", \"art\", \"shakespeare\", \"dance\", \"literature\", \"novel\", \"symphony\", \"drama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7400efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science vs Art :  0.8901759217963355\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(male_words, science_words, \n",
    "                           art_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(female_words, science_words, \n",
    "                           art_words, [\"GGG likes XXX\", \"GGG like XXX\", \"GGG is interested in XXX\"], group=True)\n",
    "\n",
    "print(\"Science vs Art : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf57092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "mental_disease = [\"sad\", \"hopeless\", \"gloomy\", \"tearful\", \"miserable\", \"depressed\"]\n",
    "\n",
    "physical_disease = [\"sick\", \"illness\", \"influenza\", \"disease\", \"virus\", \"cancer\"]\n",
    "print(len(mental_disease) == len(physical_disease))\n",
    "#attribute words\n",
    "temporary = [\"impermanent\", \"unstable\", \"variable\", \"fleeting\", \"short-term\", \"brief\", \"occasional\"]\n",
    "\n",
    "permanent = [\"stable\", \"always\", \"constant\", \"persistent\", \"chronic\", \"prolonged\", \"forever\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5fc8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mental v/s Physical disease :  0.41519951639931973\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(mental_disease, temporary, \n",
    "                           permanent, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(physical_disease, temporary, \n",
    "                           permanent, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"Mental v/s Physical disease : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "078ae236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#target words\n",
    "young_people_names = [\"tiffany\", \"michelle\", \"cindy\", \"kristy\", \"brad\", \"eric\", \"joey\", \"billy\"]\n",
    "\n",
    "old_people_names = [\"ethel\", \"bernice\", \"gertrude\", \"agnes\", \"cecil\", \"wilbert\", \"mortimer\", \"edgar\"]\n",
    "\n",
    "print(len(young_people_names) == len(old_people_names))\n",
    "#attribute words\n",
    "pleasant = [\"joy\", \"love\", \"peace\", \"wonderful\", \"pleasure\", \"friend\", \"laughter\", \"happy\"]\n",
    "\n",
    "\n",
    "unpleasant = [\"agony\", \"terrible\", \"horrible\", \"nasty\", \"evil\", \"war\", \"awful\", \"failure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dfe18ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young_people_names vs. old_people_names :  0.7060247337982326\n"
     ]
    }
   ],
   "source": [
    "df1 = get_word_bias_scores(young_people_names, pleasant, \n",
    "                           unpleasant, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "df2 = get_word_bias_scores(old_people_names, pleasant, \n",
    "                           unpleasant, [\"GGG are XXX\", \"the GGG is XXX\"], group=True)\n",
    "\n",
    "print(\"young_people_names vs. old_people_names : \",get_effect_size(df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
